import collections
import os
import pandas as pd


# Specifies the input files needed for this program
# This is the mapping between the HGNC gene name and the internal PRISM gene identifier
INPUT_FILE_HGNC_TO_GREAT_ID = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/hg38.loci"
# This is the directory that contains the output of phase 2 of the GREAT close loop analysis
INPUT_GENE_DIR = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/step_2_outputs/"
# This is the file that maps between PRISM identifier and HGNC gene name generated by David
GENE_NUM_PRISM_TO_GENE_NAME_DICT = "/cluster/u/dwwu16/PRISM/human_monomer_800/confidence_curve_generation/step_6/outputs/by_gene/lookup_table.txt"

# All data structures used
# Maps GREAT gene ID to HGNC ID
GREAT_TO_HGNC = dict()
# Maps PRISM ID made by David to HGNC ID
PRISM_ID_TO_HGNC = dict()
# Set of all PRISM IDs in our PRISM v5.0 run
ALL_PRISM_IDS = list()
# Mapping between HGNC ID to GO Biological Process Ontology IDs in PRISM v5.0 run
HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP = collections.defaultdict(list)
# Mapping between HGNC ID to GO Biological Process Ontology IDs in Ground Truth File
HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_BP = collections.defaultdict(list)
# Mapping between HGNC ID to GO Cellural Component Ontology IDs in PRISM v5.0 run
HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC = collections.defaultdict(list)
# Mapping between HGNC ID to GO Cellural Component Ontology IDs in Ground Truth File
HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_CC = collections.defaultdict(list)
# Mapping between HGNC ID to GO Molecular Function Ontology IDs in PRISM v5.0 run
HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF = collections.defaultdict(list)
# Mapping between HGNC ID to GO Molecular Function Ontology IDs in Ground Truth File
HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_MF = collections.defaultdict(list)
# Mapping between HGNC ID to MGI KO Ontology IDs in PRISM v5.0 run
HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO = collections.defaultdict(list)
# Mapping between HGNC ID to MGI KO Ontology IDs in Ground Truth File
HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_KO = collections.defaultdict(list)
# Mapping between HGNC ID to MGI Phenotype Process Ontology IDs in PRISM v5.0 run
HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO = collections.defaultdict(list)
# Mapping between HGNC ID to MGI Phenotype Process Ontology IDs in Ground Truth File
HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_PHENO = collections.defaultdict(list)


def get_dict_from_table(file, key_col, val_col, **kwargs):
	'''Read a table file and create a mapping file'''
	df = pd.read_csv(file, usecols=[key_col, val_col], **kwargs)
	d = dict(zip(df[df.keys()[0]], df[df.keys()[1]]))
	assert len(d) == df.shape[0], "ERROR IN READING {} Quitting...".format(file)
	return d


def counter_most_common_more_than(counter, count):
	'''Finds all duplicate genes'''
	n_items=len([x for x in counter.values() if x > count])
	return counter.most_common(n_items)


def main():
# Declare necessary globals
	global GREAT_TO_HGNC
	global PRISM_ID_TO_HGNC
	global ALL_PRISM_IDS
# Create mapping between GREAT ID and HGNC ID by reading in the file
	PRISM_ID_TO_HGNC = get_dict_from_table(GENE_NUM_PRISM_TO_GENE_NAME_DICT,0,1,sep='\t')

	# Create mapping between David's PRISM ID and HGNC ID by reading in the file
	GREAT_TO_HGNC = get_dict_from_table(INPUT_FILE_HGNC_TO_GREAT_ID,0,4,sep='\t',header=None)

	print('DUPLICATE GENES')
	print(counter_most_common_more_than(collections.Counter(PRISM_ID_TO_HGNC.values()), 1))
	print("TOTAL GENES: ", len(set(PRISM_ID_TO_HGNC.values())))
	ALL_PRISM_IDS = PRISM_ID_TO_HGNC.keys()
	print("TOTAL NUM PRISM IDs: ", len(ALL_PRISM_IDS))

	# reads in, for each gene in the PRISM v5.0 run (by looping over all PRISM IDs), the GREAT prediction ontology terms for that genes. Calls method "read_GREAT_output_file" on five different files, each one a different ontology we have in our library
	for PRISM_ID in ALL_PRISM_IDS:
		# hgnc ID for the PRISM ID
		hgnc_id = PRISM_ID_TO_HGNC[PRISM_ID]
		# finds all GREAT ontology prediction files
		all_relavant_files = os.listdir(INPUT_GENE_DIR + str(PRISM_ID))
		# some genes from our library did not have any PRISM binding site predictions that survivied filtering. They therefore have 0 ontology predictions, and can be skipped
		GREAT_MGI_KO_FILE = INPUT_GENE_DIR + str(PRISM_ID) + '/MGIPhenoSingleKO_filtered.tsv'
		GREAT_MGI_PHENO_FILE = INPUT_GENE_DIR + str(PRISM_ID) + '/MGIPhenotype_filtered.tsv'
		GREAT_GO_CC_FILE = INPUT_GENE_DIR + str(PRISM_ID) + '/GOCellularComponent_filtered.tsv'
		GREAT_GO_BP_FILE = INPUT_GENE_DIR + str(PRISM_ID) + '/GOBiologicalProcess_filtered.tsv'
		GREAT_GO_MF_FILE = INPUT_GENE_DIR + str(PRISM_ID) + '/GOMolecularFunction_filtered.tsv'
		if os.path.isfile(GREAT_MGI_KO_FILE) and os.path.isfile(GREAT_MGI_PHENO_FILE) and os.path.isfile(GREAT_GO_CC_FILE) and os.path.isfile(GREAT_GO_BP_FILE) and os.path.isfile(GREAT_GO_MF_FILE):
			read_GREAT_output_file(GREAT_GO_CC_FILE, HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC, hgnc_id)
			read_GREAT_output_file(GREAT_GO_BP_FILE, HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP, hgnc_id)
			read_GREAT_output_file(GREAT_GO_MF_FILE, HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF, hgnc_id)
			read_GREAT_output_file(GREAT_MGI_KO_FILE, HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO, hgnc_id)
			read_GREAT_output_file(GREAT_MGI_PHENO_FILE, HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO, hgnc_id)
		else:
			print("NO PRISM BINDING SITE PREDICTIONS: ", hgnc_id)


# Reads in a single GREAT output file with ontology predictions and stores this information in a dict
# INPUTS: FILE_NAME is the file to be read, dict_to_use is the speicific dictionary to use to store the mapping from gene to GREAT ontology predictions, depending on ontology this will change,
# line_to_skip is the header line to skip, and hgnc_id is the HGNC ID to use as the key in the dictionary
def read_GREAT_output_file(FILE_NAME, dict_to_use, hgnc_id):
	df = pd.read_csv(FILE_NAME, sep='\t', header=0)
	# Gets list of all ontology IDs present in file, and adds them to the dictionary that maps gene to all GREAT predictions
	all_ontology_terms = list(df['# ID'])
	for pheno_id in all_ontology_terms:
		dict_to_use[hgnc_id].append(pheno_id)


# Reads in all of the ground truth ontology files that map GREAT gene ID to all of the experimentally verified ontology terms
def get_ground_truth_vals():
	GO_BP_INPUT_FILE = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/GO_BP/ontoToGene.canon"
	GO_CC_INPUT_FILE = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/GO_CC/ontoToGene.canon"
	GO_MF_INPUT_FILE = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/GO_MF/ontoToGene.canon"
	MGI_KO_INPUT_FILE = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/MGI_KO/ontoToGene.canon"
	MGI_PHENO_INPUT_FILE = "/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/closed_loop_analysis_input_files/MGI_PHENO/ontoToGene.canon"
	read_single_input_file(GO_BP_INPUT_FILE, HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_BP)
	read_single_input_file(GO_CC_INPUT_FILE, HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_CC)
	read_single_input_file(GO_MF_INPUT_FILE, HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_MF)
	read_single_input_file(MGI_KO_INPUT_FILE, HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_KO)
	read_single_input_file(MGI_PHENO_INPUT_FILE, HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_PHENO)


# Reads a single ground truth ontology file into the appropriate dictionary that stores the ground truth values
def read_single_input_file(INPUT_FILE, dict_to_use):
	d = collections.defaultdict(list)
	df = pd.read_csv(INPUT_FILE, sep='\t', header=None)
	# For each GREAT gene id and ontology term, zips them togeather to create a mapping d between GREAT gene ids and all the ontology terms associated with that gene id
	for i, j in zip(df[df.columns[-1]],df[0]):
		d[i].append(j)

	for GREAT_gene_id in d:
		id_to_use = GREAT_TO_HGNC[GREAT_gene_id]
		for onto_id in d[GREAT_gene_id]:
			dict_to_use[id_to_use].append(onto_id)


# Dictionaries that store the numberator and denominator for calculating closed-loop-percentage. The numberator is the number of ontology terms for a specific ontology that were
# in the PRISM v5.0 predictions and that are experimentally confirmed. The denominator is the number of total ontology term predictions total for all genes in that ontology
total_percentage_numerator = dict()
total_percentage_numerator["GO_CC"] = 0
total_percentage_numerator["GO_BP"] = 0
total_percentage_numerator["GO_MF"] = 0
total_percentage_numerator["MGI_KO"] = 0
total_percentage_numerator["MGI_PHENO"] = 0
total_percentage_denominator = dict()
total_percentage_denominator["GO_CC"] = 0
total_percentage_denominator["GO_BP"] = 0
total_percentage_denominator["GO_MF"] = 0
total_percentage_denominator["MGI_KO"] = 0
total_percentage_denominator["MGI_PHENO"] = 0


# Makes an output file for each gene that has the following information:
# For each gene, creates a file that contains, for each of the 5 ontologies we have, the number of ontology predictions that were made for that gene by PRISM v5.0,
# the number of those predictions that are experimentally verified, and the closed loop percentage. Additionally, updates the numerator and denominator dictionaries that are right above
# this comment for calculate of ontology wide statistics
def make_output_files():
	for gene in ALL_PRISM_IDS:
		HGNC_ID_FOR_GENE = PRISM_ID_TO_HGNC[gene]
		command = "mkdir -p /cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/step_2_closed_loop_analysis/outputs/" + str(gene)
		os.system(command)
		output_file = open("/cluster/u/dwwu16/PRISM/human_monomer_800/GREAT_closed_loop_analysis/step_2_closed_loop_analysis/outputs/" + str(gene) + "/output.txt", "w+")
		# Finds all of the experimentally verified ontology terms for a particular gene for a particular ontology using a list comprehension.
		all_consistent_terms_GO_CC = [term for term in HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE] if term in HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE]]
		if len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE]) != 0:
			# writes relavant statistics to a output file
			output_file.write("GO CELLURAL COMPONENT PERCENTAGE: " + str(float(len(all_consistent_terms_GO_CC)) / len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE])) + "\n")
			output_file.write("GO CELLURAL COMPONENT NUMERATOR:" + str(len(all_consistent_terms_GO_CC)) + "\n")
			output_file.write("GO CELLURAL COMPONENT DENOMINATOR:" + str(len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE])) + "\n")
			for element in all_consistent_terms_GO_CC:
				output_file.write(element + ",")
			output_file.write("\n\n\n")
			# updates the counts for the numberator and denominator dictionaries for ontology wide statistics
			total_percentage_numerator["GO_CC"] += len(all_consistent_terms_GO_CC)
			total_percentage_denominator["GO_CC"] += len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_CC[HGNC_ID_FOR_GENE])
		else:
			output_file.write("GO CELLURAL COMPONENT PERCENTAGE: NO HITS FOUND\n")
			output_file.write("GO CELLURAL COMPONENT NUMERATOR:0\n")
			output_file.write("GO CELLURAL COMPONENT DENOMINATOR:0\n\n\n")

		# ALL code after this is just the same thing as the section previous to this comment, just with different ontologies
		all_consistent_terms_GO_BP = [term for term in HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE] if term in HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE]]
		if len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE]) != 0:
			output_file.write("GO BIOLOGICAL PROCESS PERCENTAGE: " +  str(float(len(all_consistent_terms_GO_BP)) / len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE])) + "\n")
			output_file.write("GO BIOLOGICAL PROCESS NUMERATOR:" + str(len(all_consistent_terms_GO_BP)) + "\n")
			output_file.write("GO BIOLOGICAL PROCESS DENOMINATOR:" + str(len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE])) + "\n")
			for element in all_consistent_terms_GO_BP:
				output_file.write(element + ",")
			output_file.write("\n\n\n")
			total_percentage_numerator["GO_BP"] += len(all_consistent_terms_GO_BP)
			total_percentage_denominator["GO_BP"] += len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_BP[HGNC_ID_FOR_GENE])
		else:
			output_file.write("GO BIOLOGICAL PROCESS PERCENTAGE: NO HITS FOUND\n")
			output_file.write("GO BIOLOGICAL PROCESS NUMERATOR:0\n")
			output_file.write("GO BIOLOGICAL PROCESS DENOMINATOR:0\n\n\n")

		all_consistent_terms_GO_MF = [term for term in HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE] if term in HGNC_TO_GROUND_TRUTH_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE]]
		if len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE]) != 0:
			output_file.write("GO MOLECULAR FUNCTION PERCENTAGE: " + str(float(len(all_consistent_terms_GO_MF)) / len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE])) + "\n")
			output_file.write("GO MOLECULAR FUNCTION NUMERATOR:" + str(len(all_consistent_terms_GO_MF)) + "\n")
			output_file.write("GO MOLECULAR FUNCTION DENOMINATOR:" + str(len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE])) + "\n")
			for element in all_consistent_terms_GO_MF:
				output_file.write(element + ",")
			output_file.write("\n\n\n")
			total_percentage_numerator["GO_MF"] += len(all_consistent_terms_GO_MF)
			total_percentage_denominator["GO_MF"] += len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_GO_MF[HGNC_ID_FOR_GENE])
		else:
			output_file.write("GO MOLECULAR FUNCTION PERCENTAGE: NO HITS FOUND\n")
			output_file.write("GO MOLECULAR FUNCTION NUMERATOR:0\n")
			output_file.write("GO MOLECULAR FUNCTION DENOMINATOR:0\n\n\n")

		all_consistent_terms_MGI_KO = [term for term in HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE] if term in HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE]]
		if len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE]) != 0:
			output_file.write("MGI KNOCKOUT PERCENTAGE: " + str(float(len(all_consistent_terms_MGI_KO)) / len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE])) + "\n")
			output_file.write("MGI KNOCKOUT NUMERATOR:" + str(len(all_consistent_terms_MGI_KO)) + "\n")
			output_file.write("MGI KNOCKOUT DENOMINATOR:" + str(len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE])) + "\n")
			for element in all_consistent_terms_MGI_KO:
				output_file.write(element + ",")
			output_file.write("\n\n\n")
			total_percentage_numerator["MGI_KO"] += len(all_consistent_terms_MGI_KO)
			total_percentage_denominator["MGI_KO"] += len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_KO[HGNC_ID_FOR_GENE])
		else:
			output_file.write("MGI KNOCKOUT PERCENTAGE: NO HITS FOUND\n")
			output_file.write("MGI KNOCKOUT NUMERATOR:0\n")
			output_file.write("MGI KNOCKOUT DENOMINATOR:0\n\n\n")


		all_consistent_terms_MGI_PHENO = [term for term in HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE] if term in HGNC_TO_GROUND_TRUTH_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE]]
		if len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE]) != 0:
			output_file.write("MGI PHENOTYPE PERCENTAGE: " + str(float(len(all_consistent_terms_MGI_PHENO)) / len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE])) + "\n")
			output_file.write("MGI PHENOTYPE NUMERATOR:" + str(len(all_consistent_terms_MGI_PHENO)) + "\n")
			output_file.write("MGI PHENOTYPE DENOMINATOR:" + str(len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE])) + "\n")
			for element in all_consistent_terms_MGI_PHENO:
				output_file.write(element + ",")
			output_file.write("\n\n\n")
			total_percentage_numerator["MGI_PHENO"] += len(all_consistent_terms_MGI_PHENO)
			total_percentage_denominator["MGI_PHENO"] += len(HGNC_TO_GREAT_PREDICTED_ONTOLOGY_MGI_PHENO[HGNC_ID_FOR_GENE])
		else:
			output_file.write("MGI PHENOTYPE PERCENTAGE: NO HITS FOUND\n")
			output_file.write("MGI PHENOTYPE NUMERATOR:0\n")
			output_file.write("MGI PHENOTYPE DENOMINATOR:0\n\n\n")

# Prints out closed-loop analysis statistics for the entire ontology and the average over all ontologies

# These two variable keep track of a running total of all ontologies to be used to get the average percentages over all ontologies
	total_numberator = 0
	total_denominator = 0

# Prints out ontology specific statistics
	for key in total_percentage_denominator:
		print("STATS FOR ONTOLOGY CLASS: ", key)
		print(total_percentage_numerator[key], " GREAT HITS VERIFIED. ", total_percentage_denominator[key], " GREAT HITS TOTAL. PROPORTION IS: ", float(total_percentage_numerator[key]) / total_percentage_denominator[key])
		total_numberator += total_percentage_numerator[key]
		total_denominator += total_percentage_denominator[key]

	print("AVERAGE OVER ALL ONTOLOGIES: ", float(total_numberator) / total_denominator)


main()
get_ground_truth_vals()
make_output_files()
